name: PR CI -CanPRDev Project Review # å·¥ä½œæµç¨‹åç¨±ï¼Œæ›´æ”¹ç‚º Python å°ˆæ¡ˆ | Workflow name, changed for Python projects

on:
  pull_request:
    branches:
      - main # è§¸ç™¼æ¢ä»¶ï¼šåœ¨ main åˆ†æ”¯çš„ Pull Request | Trigger condition: Pull Request to the main branch

# ç’°å¢ƒè®Šæ•¸è¨­å®š | Environment variables configuration
env:
  PYTHON_VERSION: '3.9'
  MAX_DIFF_SIZE: 6000
  OPENAI_MODEL: 'gpt-4o'
  REVIEW_TITLE: 'ğŸ¤– **AI ç¨‹å¼ç¢¼å¯©æŸ¥æ„è¦‹ | AI Code Review Feedback**'

# æ˜ç¢ºè¨­å®šæ¬Šé™ | Explicitly set permissions
permissions:
  contents: read
  pull-requests: write

jobs:
  build-and-test:
    name: Build and Test # ä½œæ¥­åç¨± | Job name
    runs-on: ubuntu-latest # åŸ·è¡Œç’°å¢ƒ | Execution environment

    steps:
      - name: Checkout code # æ­¥é©Ÿï¼šæª¢å‡ºç¨‹å¼ç¢¼ | Step: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 # ç²å–å®Œæ•´çš„ git æ­·å²è¨˜éŒ„ï¼Œä»¥ä¾¿é€²è¡Œæ›´å¥½çš„å·®ç•°æ¯”è¼ƒ | Get the complete git history for better diff comparison

      - name: Set up Python # æ­¥é©Ÿï¼šè¨­å®š Python ç’°å¢ƒ | Step: Set up Python environment
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }} # ä½¿ç”¨ç’°å¢ƒè®Šæ•¸è¨­å®š Python ç‰ˆæœ¬ | Use environment variable for Python version

      - name: Cache pip dependencies # æ­¥é©Ÿï¼šå¿«å– pip ä¾è³´ | Step: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies # æ­¥é©Ÿï¼šå®‰è£ Python ä¾è³´ | Step: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt # å®‰è£å°ˆæ¡ˆä¾è³´ | Install project dependencies
          else
            echo "No requirements.txt found, skipping dependency installation"
          fi
          # å®‰è£å¿…è¦çš„å·¥å…· | Install necessary tools
          pip install jq

      - name: Notify Review Start # æ­¥é©Ÿï¼šé€šçŸ¥å¯©æŸ¥é–‹å§‹ | Step: Notify review start
        uses: peter-evans/create-or-update-comment@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ğŸ” AI code review process started. Please wait while I analyze your code...

      - name: Get PR Diff and Determine Size # æ­¥é©Ÿï¼šç²å– PR å·®ç•°ä¸¦ç¢ºå®šå¤§å° | Step: Get PR diff and determine size
        id: diff
        run: |
          echo "Getting diff for PR #${{ github.event.pull_request.number }}"
          git fetch origin main # ç²å–ä¸»åˆ†æ”¯çš„æœ€æ–°ç‹€æ…‹ | Fetch the latest state of the main branch
          git diff origin/main > diff.txt # å°‡å·®ç•°å¯«å…¥ diff.txt æª”æ¡ˆ | Write the diff to diff.txt file
          
          # ç¢ºå®š PR å¤§å° | Determine PR size
          DIFF_SIZE=$(cat diff.txt | wc -c)
          echo "diff_size=$DIFF_SIZE" >> $GITHUB_OUTPUT
          if [ $DIFF_SIZE -gt ${{ env.MAX_DIFF_SIZE }} ]; then
            echo "is_large=true" >> $GITHUB_OUTPUT
            echo "PR is large ($DIFF_SIZE bytes), will analyze most important parts only"
          else
            echo "is_large=false" >> $GITHUB_OUTPUT
            echo "PR is manageable size ($DIFF_SIZE bytes), will analyze completely"
          fi

      - name: Process Large PR # æ­¥é©Ÿï¼šè™•ç†å¤§å‹ PR | Step: Process large PR
        if: steps.diff.outputs.is_large == 'true'
        run: |
          echo "PR is too large for complete analysis. Analyzing most important files only..."
          # å°‹æ‰¾æœ€é‡è¦çš„æª”æ¡ˆï¼ˆä¾‹å¦‚ Python æª”æ¡ˆï¼Œæ’é™¤æ¸¬è©¦æª”æ¡ˆï¼‰| Find most important files (e.g., Python files, excluding test files)
          git diff --name-only origin/main | grep -E '\.py$' | grep -v '_test\.py$' | grep -v 'test_' | head -10 > important_files.txt
          
          # åªæå–é‡è¦æª”æ¡ˆçš„å·®ç•° | Extract diff only for important files
          > filtered_diff.txt
          while IFS= read -r file; do
            echo "Including $file in analysis"
            git diff origin/main -- "$file" >> filtered_diff.txt
          done < important_files.txt
          
          # ä½¿ç”¨éæ¿¾å¾Œçš„å·®ç•°æ›¿æ›åŸå§‹å·®ç•° | Replace original diff with filtered diff
          mv filtered_diff.txt diff.txt

      # å¯é¸çš„ SonarQube æƒæ | Optional SonarQube scan
      - name: SonarQube Scan
        if: ${{ vars.USE_SONARQUBE == 'true' }}
        id: sonarqube-scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONARQUBE_TOKEN }}
          SONAR_HOST_URL: ${{ vars.SONARQUBE_URL }}
        continue-on-error: true

      - name: Call OpenAI for Review # æ­¥é©Ÿï¼šå‘¼å« OpenAI é€²è¡Œå¯©æŸ¥ | Step: Call OpenAI for Review
        id: openai_review
        continue-on-error: true # å…è¨±æ­¤æ­¥é©Ÿå¤±æ•—ä½†ç¹¼çºŒå·¥ä½œæµç¨‹ | Allow this step to fail but continue the workflow
        run: |
          echo "Calling OpenAI API to analyze code diff..."
          # é™åˆ¶ DIFF_CONTENT çš„å¤§å°ï¼Œä»¥é¿å…è¶…é OpenAI API çš„ Token é™åˆ¶
          # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ head -c ${{ env.MAX_DIFF_SIZE }} é™åˆ¶å­—ç¯€æ•¸ï¼Œç¢ºä¿ diff æª”æ¡ˆä¸æœƒå¤ªå¤§
          # Limit DIFF_CONTENT size to avoid exceeding OpenAI API Token limits.
          # Note: Using head -c ${{ env.MAX_DIFF_SIZE }} to limit bytes, ensuring the diff file isn't too large.
          DIFF_CONTENT=$(cat diff.txt | head -c ${{ env.MAX_DIFF_SIZE }} | jq -Rs .)

          # æ§‹å»ºå‚³é€çµ¦ OpenAI API çš„ JSON è«‹æ±‚è³‡æ–™ | Construct the JSON request data for the OpenAI API
          REQUEST_DATA=$(jq -n \
            --arg model "${{ env.OPENAI_MODEL }}" \
            --arg system_msg "ä½ æ˜¯ä¸€ä½è³‡æ·±ç¨‹å¼ç¢¼å¯©æŸ¥å“¡ï¼Œå°ˆé•·åœ¨æ–¼æ‰¾å‡ºæŠ€è¡“å‚µã€é‡æ§‹å»ºè­°èˆ‡ clean code å’Œ SOLID åŸå‰‡ã€‚è«‹ç‰¹åˆ¥æ³¨æ„ Python ç¨‹å¼ç¢¼çš„æ…£ä¾‹å’Œæœ€ä½³å¯¦è¸ã€‚" \
            --arg user_msg "ä»¥ä¸‹æ˜¯ pull request çš„ç¨‹å¼ç¢¼å·®ç•°ï¼Œè«‹æŒ‡å‡ºæ˜¯å¦æœ‰æŠ€è¡“å‚µã€å£å‘³é“ã€ç¶­è­·é¢¨éšªã€å®‰å…¨æ€§å•é¡Œï¼Œä¸¦çµ¦å‡ºé‡æ§‹å»ºè­°ï¼š\n\n$(cat diff.txt | head -c ${{ env.MAX_DIFF_SIZE }})" \
            '{
              model: $model,
              temperature: 0.7,
              messages: [
                { role: "system", content: $system_msg },
                { role: "user", content: $user_msg }
              ]
            }')

          echo "ğŸŸ¡ Sending this request to OpenAI:"
          echo "$REQUEST_DATA" | jq . # é¡¯ç¤ºå‚³é€çš„è«‹æ±‚è³‡æ–™ï¼ˆç¾åŒ–è¼¸å‡ºï¼‰ | Display the request data sent (prettified output)

          # ä½¿ç”¨ curl å‘¼å« OpenAI API | Call OpenAI API using curl
          RESPONSE=$(curl https://api.rdsec.trendmicro.com/prod/aiendpoint/v1/ \
            -s \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}" \
            -H "extra-parameters: pass-through" \
            -d "$REQUEST_DATA")
          
          # æª¢æŸ¥ API å‘¼å«æ˜¯å¦æˆåŠŸ | Check if API call was successful
          if [ $? -ne 0 ] || [ -z "$RESPONSE" ] || [[ "$RESPONSE" == *"error"* ]]; then
            echo "api_error=true" >> $GITHUB_OUTPUT
            echo "Error calling OpenAI API or receiving response" > review.txt
            echo "$RESPONSE" >> api_error.log
          else
            echo "api_error=false" >> $GITHUB_OUTPUT
            echo "ğŸŸ¢ OpenAI å›æ‡‰å…§å®¹ï¼š"
            echo "$RESPONSE" | jq . # é¡¯ç¤º OpenAI çš„å›æ‡‰ï¼ˆç¾åŒ–è¼¸å‡ºï¼‰ | Display OpenAI's response (prettified output)

            # å¾å›æ‡‰ä¸­æå–å¯©æŸ¥å…§å®¹ä¸¦å¯«å…¥ review.txt | Extract review content from the response and write to review.txt
            echo "$RESPONSE" | jq -r '.choices[0].message.content' > review.txt
          fi

          # è™•ç†æ›è¡Œç¬¦ï¼Œä»¥ä¾¿åœ¨ GitHub è©•è«–ä¸­æ­£ç¢ºé¡¯ç¤º
          # Process newlines for correct display in GitHub comments
          REVIEW_CONTENT=$(cat review.txt | perl -pe 's/\\n/\n/g')
          # å°‡å¯©æŸ¥å…§å®¹è¨­å®šç‚ºæ­¥é©Ÿçš„è¼¸å‡º | Set the review content as the step's output
          echo "review<<EOF" >> $GITHUB_OUTPUT
          echo "$REVIEW_CONTENT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Comment on PR # æ­¥é©Ÿï¼šåœ¨ PR ä¸Šè©•è«– | Step: Comment on PR
        uses: peter-evans/create-or-update-comment@v3 # ä½¿ç”¨ç¬¬ä¸‰æ–¹ Action å»ºç«‹æˆ–æ›´æ–°è©•è«– | Use a third-party Action to create or update a comment
        with:
          token: ${{ secrets.GITHUB_TOKEN }} # ä½¿ç”¨ GitHub æä¾›çš„ Token é€²è¡Œèº«ä»½é©—è­‰ | Use the GitHub-provided Token for authentication
          issue-number: ${{ github.event.pull_request.number }} # è©•è«–çš„ PR ç·¨è™Ÿ | PR number for the comment
          body: | # è©•è«–å…§å®¹ | Comment body
            ${{ env.REVIEW_TITLE }}

            ${{ steps.diff.outputs.is_large == 'true' && 'âš ï¸ **Note**: This PR is large, so only the most important files were analyzed.' || '' }}
            ${{ steps.openai_review.outputs.api_error == 'true' && 'âŒ **Error**: There was an issue with the OpenAI API call. Please check the workflow logs.' || '' }}
            
            ä»¥ä¸‹æ˜¯ OpenAI ${{ env.OPENAI_MODEL }} å°æ­¤ PR çš„åˆ†æèˆ‡å»ºè­°ï¼š
            Here are the analysis and suggestions from OpenAI ${{ env.OPENAI_MODEL }} for this PR:

            ${{ steps.openai_review.outputs.review }} # å¼•ç”¨ OpenAI å¯©æŸ¥æ­¥é©Ÿçš„è¼¸å‡º | Reference the output from the OpenAI review step
            
            ${{ steps.sonarqube-scan.outcome == 'success' && 'âœ… **SonarQube scan completed successfully**' || '' }}

      - name: Run Python tests # æ­¥é©Ÿï¼šåŸ·è¡Œ Python æ¸¬è©¦ | Step: Run Python tests
        id: tests
        continue-on-error: true # å…è¨±æ¸¬è©¦å¤±æ•—ä½†ç¹¼çºŒå·¥ä½œæµç¨‹ | Allow tests to fail but continue the workflow
        run: |
          echo "Running Python tests..."
          # æª¢æŸ¥æ˜¯å¦æœ‰ pytest.ini æˆ– test ç›®éŒ„ | Check if pytest.ini or test directory exists
          if [ -f "pytest.ini" ] || [ -d "tests" ] || [ -d "test" ]; then
            pip install pytest pytest-cov
            pytest --cov=./ --cov-report=xml || echo "test_failed=true" >> $GITHUB_OUTPUT
            echo "test_status=$?" >> $GITHUB_OUTPUT
          else
            echo "No pytest configuration or test directory found, skipping tests"
            echo "test_status=skipped" >> $GITHUB_OUTPUT
          fi

      - name: Report Test Results # æ­¥é©Ÿï¼šå ±å‘Šæ¸¬è©¦çµæœ | Step: Report test results
        if: steps.tests.outputs.test_status != 'skipped'
        uses: peter-evans/create-or-update-comment@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ## ğŸ§ª Test Results
            
            ${{ steps.tests.outputs.test_failed == 'true' && 'âŒ **Tests failed**. Please check the workflow logs for details.' || 'âœ… **Tests passed successfully**.' }}

      - name: Workflow Summary # æ­¥é©Ÿï¼šå·¥ä½œæµç¨‹æ‘˜è¦ | Step: Workflow summary
        run: |
          echo "## ğŸ” PR Review Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- PR #${{ github.event.pull_request.number }}" >> $GITHUB_STEP_SUMMARY
          echo "- Diff size: ${{ steps.diff.outputs.diff_size }} bytes" >> $GITHUB_STEP_SUMMARY
          echo "- OpenAI model used: ${{ env.OPENAI_MODEL }}" >> $GITHUB_STEP_SUMMARY
          echo "- API error: ${{ steps.openai_review.outputs.api_error || 'false' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Test status: ${{ steps.tests.outputs.test_status || 'not run' }}" >> $GITHUB_STEP_SUMMARY
